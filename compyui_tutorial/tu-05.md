# ComfyUI 인페인트 기법

ComfyUI로 인페인트를 적용하는 것은 AUTOMATIC1111을 사용할 때만큼 쉽지 않습니다. [ComfyUI 예제 사이트](https://comfyanonymous.github.io/ComfyUI_examples/inpaint/)에 올라온 워크플로를 포함해서 실제로 적용해보면 에러가 발생하는 경우가 많습니다. 이 글에서는 좀 더 괜찮은 인페인트 워크플로를 몇개 올립니다. 사실 저는 여기에 있는 워크플로보다, 엊그제 올린 [자동 인페인트/아웃페인트 - ComfyUI 워크플로](https://www.internetmap.kr/entry/Auto-Inpaint-Outpaint-with-ComfyUI)가 제일 마음에 듭니다만, 이 글도 참고하시길. 

- [소프트웨어](https://www.internetmap.kr/entry/ComfyUI-inpaint#software)
- [워크플로 활용방법](https://www.internetmap.kr/entry/ComfyUI-inpaint#workflow)
- [일반 모델을 사용한 인페인트](https://www.internetmap.kr/entry/ComfyUI-inpaint#standard)
- [인페인트 모델을 사용한 인페인트](https://www.internetmap.kr/entry/ComfyUI-inpaint#inpaint)
- [콘트롤넷 인페인트](https://www.internetmap.kr/entry/ComfyUI-inpaint#controlnet)
- [FaceDetailer 자동 얼굴 수정](https://www.internetmap.kr/entry/ComfyUI-inpaint#adetailer)
- [기존 사진의 얼굴 수정](https://www.internetmap.kr/entry/ComfyUI-inpaint#existing)

## 소프트웨어

이 글에서는 오픈소스 이미지 생성 AI 인 스테이블 디퓨전(Stable Diffusion)의 대표적인 GUI 중 하나인 ComfyUI를 사용합니다. [설치 방법 및 사용법 기초](https://www.internetmap.kr/entry/Stable-Diffusion-via-ComfyUI), [초보자 가이드](https://www.internetmap.kr/entry/ComfyUI)를 읽어보세요.

## 워크플로 활용방법

이 글에서는 4가지 워크플로가 그림으로 올려져 있습니다. 그 그림을 다운로드 받은 후, ComfyUI 화면에 Drag&Drop하면 해당 워크플로를 사용할 수 있습니다. 

하지만, 때때로 오류가 발생할 수 있습니다. 그러한 경우, 다음과 같은 작업이 필요할 수 있습니다.

- 처음 사용할 때 - [ComfyUI Manager 를 설치](https://www.internetmap.kr/entry/Helpful-tips-for-ComfyUI#manager)해야 합니다.
- ComfyUI를 오랜만에 사용할 때 - [ComfyUI를 최신버전으로 업데이트](https://www.internetmap.kr/entry/Helpful-tips-for-ComfyUI#update)해야 합니다.
- 노드가 없다고 (빨간색) 경고가 뜰 때 - [빠진 커스톰 노드를 가져오기](https://www.internetmap.kr/entry/Helpful-tips-for-ComfyUI#load)해야 합니다.
- 불러오기 혹은 수행중 에러 발생시 - [커스톰 노드를 업데이트](https://www.internetmap.kr/entry/Helpful-tips-for-ComfyUI#update)해야 합니다.

## 일반 모델을 사용한 인페인트

이 워크플로는 인페인트 모델이 아닌 일반 모델을 사용하여 인페인트하기 위한 워크플로입니다. 이 기법은 AUTOMATIC1111 인페인트에서 ("only masked" 대신) "whole picture" 옵션을 켜고 실행하는 것과 유사합니다. 워크플로는 아래와 같습니다. 

![](https://blog.kakaocdn.net/dn/Ui4j6/btsC4GJ6lpk/25DuAUTdDmOb46IANQWfgK/img.png)

이 워크플로는 SD 1.5 버전도, SDXL 모델도 잘 작동합니다. 다만, 인페인트 모델을 사용하면 문제가 발생합니다. 인페인트 모델을 사용할 경우에는 다음 절을 참고하세요.

이 워크플로는 [ComfyUI 인페인트 예제사이트](https://comfyanonymous.github.io/ComfyUI_examples/inpaint/)에 포함된 워크플로를 약간 수정한 것입니다. 아래 왼쪽은 예제사이트의 워크플로, 오른쪽은 이 글에서 제시하는 워크플로로, [VAE Encode(for inpainting)] 노드 대신 [VAE Encode]와 [Set Latent Noise Mask]로 대체한 것을 알 수 있습니다.

|   |   |
|---|---|
|![](https://blog.kakaocdn.net/dn/uYdgP/btsC2CIgkE9/2Psoe6VSmT6zkUtKZcFCsk/img.png)|![](https://blog.kakaocdn.net/dn/ofCTw/btsC4KFOglq/Q4kel0m9JHezQ1Ic5Kltnk/img.png)|

#### 사용방법

먼저 모델 파일을 지정합니다. 이 글에서는 [Realistic Vision 모델](https://civitai.com/api/download/models/245598?type=Model&format=SafeTensor&size=full&fp=fp16)을 사용합니다. 다운로드 받은 후, ComfyUI\models\checkpoints 폴더에 넣어줍니다. 그 다음 화면을 새로고침(F5)하고 [Load checkpoint] 노드에 원하는 체크포인트 파일을 지정합니다 (AUTOMATIC1111과 파일을 공유하는 경우에는 [여기](https://www.internetmap.kr/entry/Helpful-tips-for-ComfyUI#automatic)를 보세요).  

![](https://blog.kakaocdn.net/dn/bxlAuY/btsC4d2tuEq/49R6qb5cVUNhOPPK7CLXy0/img.png)

다음으로 인페인트할 이미지를 불러옵니다. 저는 배우 유연석 사진을 사용합니다. 아래 사진을  사용하셔도 됩니다. 

![](https://blog.kakaocdn.net/dn/LWpiz/btsC39TloPx/sIxHAgR47gzGPBP5CTlo80/img.jpg)

이 사진을 [Load Image] 노드에서 선택한 뒤, 우클릭하여 메뉴를 부르고 [Open in MaskEditor] 를 선택하여 마스크를 그리고 저장해줍니다. 

![](https://blog.kakaocdn.net/dn/bAtOWN/btsC6qG1UwR/hpZK0fPyikUmsQwxlAgXyK/img.png)

프롬프트는 아래와 같이 지정합니다.

> 프롬프트: a man with a sunglasses  
> 부정적 프롬프트: disfigure, deformed, ugly

아래는 생성 결과입니다. 꽤 잘 나왔네요.

|   |   |
|---|---|
|![](https://blog.kakaocdn.net/dn/o6VwH/btsC35pUFDp/1lkpQfNTgFftcask7DEba0/img.png)|![](https://blog.kakaocdn.net/dn/dAPJm3/btsC7mYulvP/IJrOGS0gb9lfygYAD7odj1/img.png)|

아래는  [ComfyUI 인페인트 예제사이트](https://comfyanonymous.github.io/ComfyUI_examples/inpaint/)의 워크플로를 사용해 생성한 결과입니다. 마스크 영역 전체를 채우려고 한 건지 선글라스가 너무 커서 어울리지가 않네요.

|   |   |
|---|---|
|![](https://blog.kakaocdn.net/dn/c1nkIA/btsC2wH3o72/SpqxI12t39UkaNakNn2qk1/img.png)|![](https://blog.kakaocdn.net/dn/U2crV/btsC4wngmWn/KKReDXFuobb5KvxlZ1SA8k/img.png)|

#### 참고사항

필요하시면 적절하게 프롬프트를 수정해볼 수 있습니다. [원본 글](https://stable-diffusion-art.com/inpaint-comfyui/)에서는 "a man wearing sunglasses, epic style, super hero, highly detailed"이라고 좀 더 길게 지정했네요. 

그리고 [KSampler]노드의 "denoising strength"를 높이면 이미지가 좀더 많이 변형됩니다. 참고로 이 워크플로에서는 잠음 제거 강도(Denoising strength)를 0.5로 지정했지만, 뒤쪽의 워크플로에서는 이 값을 크게 지정합니다. 

## 인페인트 모델을 사용한 인페인트

인페인트 모델을 사용한 인페인트 워크플로는  [ComfyUI 인페인트 예제사이트](https://comfyanonymous.github.io/ComfyUI_examples/inpaint/)에 포함된 워크플로를 거의 그대로 사용합니다. 다만, 모델과 이미지만 바뀌었을 뿐입니다.

![](https://blog.kakaocdn.net/dn/cp83YM/btsC4pBKbha/0k5L0k3ncEqdppyUbKQTv1/img.png)

모델은 [Realistic Vision Inpainting 모델](https://civitai.com/api/download/models/245627?type=Model&format=SafeTensor&size=full&fp=fp16)을 사용합니다. 모델을 불러오는 방법, 이미지를 불러오는 방법등은 위에서 설명했으므로 생략합니다.

아래는 생성 결과입니다. 몇번 생성했는데 선글라스가 위로 배치되어서 얼굴이 길쭉해져버렸네요. ㅠㅠ 잡음 제거 강도를 변경시켜도 마찬가지네요. 

|   |   |
|---|---|
|![](https://blog.kakaocdn.net/dn/FgSTN/btsC8TuZeDn/uD02UWlj0qcksOnjhiy0bk/img.png)|![](https://blog.kakaocdn.net/dn/cleLip/btsC4wt4Bhd/NpqOGtqh7y3EFv9RcxGRRk/img.png)|

흠... 마스크를 생성할 때 눈썹을 약간 남겼더니 선글라스 위치가 내려가네요. 이제야 사람같아 보입니다. ㅎㅎ

|   |   |
|---|---|
|![](https://blog.kakaocdn.net/dn/bnlI9G/btsC8P7cQz8/8gIomAVqEMNQyuUv8eyAE0/img.png)|![](https://blog.kakaocdn.net/dn/bDkeeq/btsC87tc4ya/5WPwXkVvmghtBQmmpi0Pik/img.png)|

## 콘트롤넷 인페인트

위의 두가지 워크플로의 경우 단점이 존재합니다. [일반 모델 인페인트](https://www.internetmap.kr/entry/ComfyUI-inpaint#standard)의 경우 잡음 제거 강도를 높일 수 없고, [인페인트 모델을 사용한 인페인트](https://www.internetmap.kr/entry/ComfyUI-inpaint#inpaint)의 경우 잡음 제거 강도를 낮추면 이상해집니다. 

여기에서 소개하는 [ControlNet](https://www.internetmap.kr/entry/ComfyUI-ControlNet) 인페인트를 사용한 인페인트의 경우, 일반 스테이블 디퓨전을 사용하면서도 잡음 제거 강도를 높일 수 있는 장점이 있습니다.

아래가 워크플로입니다. 위의 예들보다 조금 더 복잡합니다.

![](https://blog.kakaocdn.net/dn/cVS0eW/btsC9oBxpRf/9xFw7I28kT5NTVdIkDQPIK/img.png)

여기에서 인페인트 콘트롤넷과 관련된 부분은 아래 그림과 같습니다. [ApplyControlNet] 노드는 [Load ControlNet Model] 노드로부터 모델을 입력받고, [Inpaint Preprocessor]로부터 참조 이미지를 입력 받습니다. [Input Preprocessor] 노드는 원본 이미지와 마스크를 입력받아 콘트롤넷 노드가 사용할 수 있는 형태로 바꿔줍니다.

![](https://blog.kakaocdn.net/dn/bUIQK7/btsC2ylBzhz/QQFhqkVlkTP5kl4IfLuwhK/img.png)

이 워크플로에서 사용하는 체크포인트 모델은 [Realistic Vision 모델](https://civitai.com/api/download/models/245598?type=Model&format=SafeTensor&size=full&fp=fp16)입니다. 콘트롤넷 모델은 [여기](https://huggingface.co/lllyasviel/ControlNet-v1-1/blob/main/control_v11p_sd15_inpaint.pth)에서 다운로드 받으시면 됩니다. 다운로드 받을 폴더는 각각 ComfyUI\models\checkpoints, ComfyUI\models\controlnet 입니다 (AUTOMATIC1111과 파일을 공유하는 경우에는 [여기](https://www.internetmap.kr/entry/Helpful-tips-for-ComfyUI#automatic)를 보세요). 

이 워크플로는 기본적으로 맨 처음에 있는 일반 모델을 사용한 인페인트 기법과 동일합니다. 배경도 달라진다는 점 외에는 결과물도 비슷하고요. 다만, 잡음 제거 강도(Denoising Strength)를 높은 값까지 올릴 수 있습니다. 아래는 0.9로 설정해서 생성한 결과입니다.

|   |   |
|---|---|
|![](https://blog.kakaocdn.net/dn/cmoeNG/btsC6VGWhfR/mFWFDHuXKshDYv5ekgEWik/img.png)|![](https://blog.kakaocdn.net/dn/GvkHi/btsC8WrQ9Bl/dT1zCoT298iR5QMqwxIJW1/img.png)|

## FaceDetailer 자동 얼굴 수정

AUTOMATIC1111 의 [ADetailer 확장](https://www.internetmap.kr/entry/Stable-Diffusion-After-Detailer)은 얼굴을 자동적으로 인페인트해주는 확장입니다.  스테이블 디퓨전을 사용해서 인물을 생성할 때 얼굴이 작은 경우(특히 SD 1.5 모델의 경우), 얼굴이 찌끄러지는 경우가 종종 발생합니다. ADetailer 는 생성된 이미지에서 얼굴을 인식하여 큰 이미지로 만든 후, 다시 생성을 하고 다시 축소시켜 원 위치에 복구시키는 방식으로 얼굴을 수정합니다. ComfyUI의 경우에는 [Impact Pack](https://github.com/ltdrdata/ComfyUI-Impact-Pack) 커스톰 노드에 있는 FaceDetailer를 사용하여 동일한 작업을 할 수 있습니다. 

다만 이 인페인트 기법은 작업자가 수정하고자하는 부분을 마스크로 지정하는 일반적인 인페인트 기법과는 다르니 참고하세요.

FaceDetailer가 포함된 Txt2img 워크플로는 아래와 같습니다.

![](https://blog.kakaocdn.net/dn/ZpqgG/btsC9xL3Cgy/uC6RMlY7aOpYJKqm40V4UK/img.png)

이 워크플로의 가장 핵심은 [FaceDetailer] 노드입니다. 이 노드는 (txt2img에 사용되는 여러가지 모델과 함께) KSampler에서 생성된 이미지를 입력받아 얼굴을 수정한 이미지를 생성해줍니다.

![](https://blog.kakaocdn.net/dn/PprGW/btsC50Ixlpu/aQQeYntZtfkoRZdIryF7M1/img.png)

얼굴을 감지하는 모델은 [UltralyticsDetectorProvider] 노드에서 선택을 하는데, 여기에서는 얼굴을 감지하는 face_yolo 모델을 사용했습니다.

![](https://blog.kakaocdn.net/dn/GGdtj/btsC6VtnQMV/l904OsR7evbkxkS888aPjk/img.png)

아래는 생성된 결과입니다. 얼굴이 완전히 다름을 아실 수 있을 겁니다.

|   |   |
|---|---|
|![](https://blog.kakaocdn.net/dn/cmJBEd/btsC8SprlFW/fM4flIWV8LKrJFAHAnLfQk/img.png)|![](https://blog.kakaocdn.net/dn/dhlKIo/btsC4cW0wmI/m9bnaStnD4ZdaaCGjzNZx0/img.png)|

참고로, [FaceDetailer] 노드에도 [KSampler] 노드와 비슷한 매개변수들이 들어 있는데, 여기에서 잡음 제거 강도(Denoising strength)를 올리면 변경이 많이 일어나게 됩니다.

## 기존 사진의 얼굴 수정

아래는 이미지를 생성하는 대신, 기존의 이미지를 수정하도록 위의 워크플로를 약간 수정한 워크플로입니다.

![](https://blog.kakaocdn.net/dn/IrLNZ/btsC6ScmXsN/3oJ3QmPne9fCwrKT4TKw2K/img.png)

이미지를 생성하는 [KSampler] 노드만 없고 위와 동일하다는 것을 아실 수 있을 겁니다. 아래 왼쪽은 위와 동일한 이미지이고, 오른쪽은 [ChilloutMix 모델](https://www.internetmap.kr/entry/Stable-Diffusion-Everything-about-models#chilloutmix)을 사용해서 나온 결과입니다.

|   |   |
|---|---|
|![](https://blog.kakaocdn.net/dn/w7tRE/btsC1op8yK7/keCITldyTKugD2nBXNqebk/img.png)|![](https://blog.kakaocdn.net/dn/bRJsv4/btsC74wQwaa/5NPdX8KccSuP4yKkBlAm7K/img.png)|

이상입니다. 이 글은 [https://stable-diffusion-art.com/inpaint-comfyui/](https://stable-diffusion-art.com/inpaint-comfyui/)을 번역하면서 이미지는 대체하고 약간 수정하여 작성한 글입니다.